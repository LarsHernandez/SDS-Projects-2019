---
title: "M1 Mini Assignment 1"
author: "Lars Nielsen"
date: "9/9/2019"
output:
  pdf_document:
    toc: yes
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
---

# M1 Mini-Assignment 1

### Link to github .Rmd https://github.com/LarsHernandez/SDS-Projects-2019/blob/master/M1_assignment_1/assignment.Rmd 
You are given 2 datasets from https://nomadlist.com/ - A community page for remote workersworldwide.

- The trips data holds ~46k individual trips of travellers on the platform https://github.com/SDS-AAU/M1-2019/raw/master/data/trips.csv

- People contains some personal information on 4k travelers https://github.com/SDS-AAU/M1-2019/raw/master/data/people.csv

- Finally, you find a countrylist file that holds countrycodes, contrynames and region-associations https://github.com/SDS-AAU/M1-2019/raw/master/data/countrylist.csv

```{r message=FALSE, warning=FALSE}
library(data.table)
library(ggplot2)
library(magrittr)

# I load the data with fread (to the one doing the peer review i'm sorry but the
# assignment is done in data.table, hope you can understand what is happening, also
# ill just do notes here in the code chunks, and only where i don't think it's
# obvious what is happening)

trips       <- fread("https://github.com/SDS-AAU/M1-2019/raw/master/data/trips.csv")
people      <- fread("https://github.com/SDS-AAU/M1-2019/raw/master/data/people.csv")
countrylist <- fread("https://github.com/SDS-AAU/M1-2019/raw/master/data/countrylist.csv")
```

Your solution approach is more important than the results obtained! Comment your notebook well, explaining all the steps of your analysis. Small technicalexplanations can go as comments in the code. Broader explanations should be inserted asmarkdown cells.Remember that notebooks execute sequentially.

Submission: Wednesday 11.9. 12:00. 

Peergrade.io (link + submission details will be sent out onMonday, 9.9)

## 1. Preprocessing
### a. Trips: transform dates into timestamps 
(note: in Python, you will have to ‘coerce’ errors forfaulty dates)
```{r}
trips[,c("date_end", "date_start") := .(as.Date(date_end, "%Y-%m-%d"), 
                                        as.Date(date_start, "%Y-%m-%d"))]
class(trips$date_end)
head(trips$date_end, 5)
```  


### b. Calculate trip duration in days 
(you can use loops, list comprehensions ormap-lambda-functions (python) to create a column that holds the numerical value of theday. You can also use the “datetime” package.)
```{r}
trips[, dur_days := date_end - date_start]

class(trips$dur_days)
head(trips$dur_days, 5)
```  


### c. Filter extreme (fake?) observations 
for durations as well as dates - start and end (trips thatlast 234565 days / are in the 17th or 23rd century)The minimum duration of a trip is 1 day!Hint: use percentiles/quantiles to set boundaries for extreme values - between 1 and 97, calculate and store the boundaries before subsetting. Rhint: Use percent_rank(as.numeric(variable)) to create percentiles
```{r message=FALSE, warning=FALSE}
trips[, quantile := dplyr::percent_rank(as.numeric(trips$dur_days))]
trips_s <- trips[quantile >= 0.01 & quantile <= 0.97]

# The range before and after the subsetting by the quantiles: 
range(na.omit(trips$dur_days))
range(trips_s$dur_days)
```

  
### d. Join the countrylist data 
to the trips data-frame using the countrycode as a key
```{r}
countrylist[, country_code := alpha_2]
# United Kingdom coded as both UK and GB
trips_s$country_code[trips_s$country_code == "UK"] <- "GB"
# Empty country codes coded as africa in countrylist
trips_s$country_code[trips_s$country_code == ""]   <- "empty"

trips_s[countrylist, on = "country_code", 
        c("region", "sub_region") := .(i.region, i.sub_region)]

head(trips_s[,.(country_code, dur_days, region, sub_region)])
```








## 2. People
### a. How many people have at least a “High School” diploma? 
```{r}
people_s <- people[education_raw != ""]
table(people_s$education_raw)

paste0("There are ",people_s[,.N], " individuals in the dataset now that has atleast High School")
```


### b. How many people working with “Software Dev” have a “Master's Degree”?
```{r}
res <- people_s[work_raw %like% "Software Dev" & education_raw %like% "Master", .N]

paste0("There are ", res, " induviduals who work with software development and have a masters degree")
```


### c. Who is the person ... 
with a Master's Degree that has the highest number of followers?[Explore who this person is. :-) ]
```{r}
res <- people_s[education_raw %like% "Master"][order(-followers)]

head(res[,c("username", "followers")])
people_s[username == "@levelsio"]
```




## 3. Trips
### a. Which country received the highest number of trips?
```{r}
a <- trips_s[, .N, by = country][order(-N)]
head(a)
```

  
### b. Which country received the highest number of trips in 2017? 
Use the start of trips as a timereference.  (python: use datetimeindex created in 1 as a selector)?Rhint: Use functions from lubridate package to extract year.

```{r}
b <- trips_s[year(date_start) == 2017, .N, by = country][order(-N)]
head(b)
```
  
  
### c. Which is the country in 'Eastern Asia' ...
where travellers spent on average least time whengoing there? Provide a visualization.
```{r}
c <- trips_s[sub_region == 'Eastern Asia', .(mean_dur = mean(dur_days), total = .N), by = country][order(mean_dur)]
c

ggplot(c, aes(reorder(country, mean_dur), mean_dur)) + 
  geom_col() + 
  scale_y_continuous() +
  labs(title = "Mean duration of stay in East Asian countries")
```


### d. Do nomads that ...
indicate working in “Software Dev” tend to have shorter or longer trips onaverage?
```{r}
trips_s[people, on = "username", c("work_raw") := .(i.work_raw)]
trips_s[, dev := work_raw %like% "Software Dev"]
trips_s[,.(mean_dur = mean(dur_days)), by = dev]
```

  
### e. Visualize over-time median trip duration 
overall (bonus: and split by world-region).You will get a weird looking plot :-)
```{r}
e1 <- trips_s[, .(mean_dur = mean(dur_days)), by = year(date_start)][
  year>1970 & year < 2019]

ggplot(e1, aes(year, mean_dur)) + 
  scale_y_continuous() +
  geom_line(size=1) + 
  labs(title="Over-time median trip duration overall")

e2 <- trips_s[, .(mean_dur = mean(dur_days)), by = .(year(date_start), region)][
  year>1970 & year < 2019]

ggplot(e2, aes(year, mean_dur)) + 
  scale_y_continuous() +
  geom_line(size=1) + 
  facet_wrap(~region) + 
  labs(title="Over-time median trip duration overall - by region")

# How manny NA's do we still have?
table(trips_s$region, useNA="always")

# What are those codes that it doesn't know
vec <- sort(table(trips_s$country_code, is.na(trips_s$region))[,2])
subset(vec, vec >0)

```

```{r fig.height=6, fig.width=8}
# Two extra plots

trips_s[, .N, by = .(year(date_start), region)][year>1970 & year < 2019] %>% 
  tidyr::complete(year, tidyr::nesting(region), fill = list(N = 0)) %>% 
  ggplot(aes(year, N, fill = region)) + 
  scale_fill_viridis_d() +
  geom_area(position = "fill") + 
  labs(title="Percentage of trips per year - by region") + 
  theme_minimal()

trips_s[, .N, by = .(year(date_start), sub_region)][year>1970 & year < 2019] %>% 
  tidyr::complete(year, tidyr::nesting(sub_region), fill = list(N = 0)) %>% 
  ggplot(aes(year, N, fill = sub_region)) + 
  scale_fill_viridis_d(option="magma") +
  geom_area(position = "fill") + 
  labs(title="Percentage of trips per year - by subregion") + 
  theme_minimal()

```

































